{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs\n",
    "\n",
    "data = pd.read_csv('quora_duplicate_questions.tsv', sep='\\t')\n",
    "data = data.drop(['id', 'qid1', 'qid2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# length based features\n",
    "data['len_q1'] = data.question1.apply(lambda x: len(str(x)))\n",
    "data['len_q2'] = data.question2.apply(lambda x: len(str(x)))\n",
    "# difference in lengths of two questions\n",
    "data['diff_len'] = data.len_q1 - data.len_q2\n",
    "\n",
    "# character length based features\n",
    "data['len_char_q1'] = data.question1.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "data['len_char_q2'] = data.question2.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "\n",
    "# word length based features\n",
    "data['len_word_q1'] = data.question1.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "data['len_word_q2'] = data.question2.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "\n",
    "# common words in the two questions\n",
    "data['common_words'] = data.apply(lambda x: \n",
    "len(set(str(x['question1'])\n",
    ".lower().split())\n",
    ".intersection(set(str(x['question2'])\n",
    ".lower().split()))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_1 = ['len_q1', 'len_q2', 'diff_len', 'len_char_q1', \n",
    "        'len_char_q2', 'len_word_q1', 'len_word_q2',     \n",
    "        'common_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fuzzy features\n",
    "data['fuzz_QRatio'] = data.apply(lambda x: fuzz.QRatio(\n",
    "str(x['question1']), str(x['question2'])), axis=1)\n",
    "data['fuzz_WRatio'] = data.apply(lambda x: fuzz.WRatio(\n",
    "str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_ratio'] = data.apply(lambda x: \n",
    "fuzz.partial_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_token_set_ratio'] = data.apply(lambda x:\n",
    "fuzz.partial_token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: \n",
    "fuzz.partial_token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_token_set_ratio'] = data.apply(lambda x: \n",
    "fuzz.token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "data['fuzz_token_sort_ratio'] = data.apply(lambda x: \n",
    "fuzz.token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_2 = ['fuzz_QRatio', 'fuzz_WRatio', 'fuzz_partial_ratio', \n",
    "                'fuzz_partial_token_set_ratio', 'fuzz_partial_token_sort_ratio',\n",
    "                'fuzz_token_set_ratio', 'fuzz_token_sort_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "      <th>fuzz_QRatio</th>\n",
       "      <th>fuzz_WRatio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345176</th>\n",
       "      <td>Can I make money online?</td>\n",
       "      <td>What are the easiest ways to make good money u...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>-40</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>86</td>\n",
       "      <td>58</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388401</th>\n",
       "      <td>What is 1?</td>\n",
       "      <td>What is √-1?</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>-2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53958</th>\n",
       "      <td>Which would be better for professional bloggin...</td>\n",
       "      <td>Which blog platform is better: WordPress or Bl...</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>86</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>Is India still considered to be a third world ...</td>\n",
       "      <td>Is mexico a third world country?</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>86</td>\n",
       "      <td>78</td>\n",
       "      <td>100</td>\n",
       "      <td>65</td>\n",
       "      <td>87</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244924</th>\n",
       "      <td>I know that the Milky Way is the Galaxy holds ...</td>\n",
       "      <td>Why didn't any of the other planets in the Sol...</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>151</td>\n",
       "      <td>-42</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "345176                           Can I make money online?   \n",
       "388401                                         What is 1?   \n",
       "53958   Which would be better for professional bloggin...   \n",
       "16213   Is India still considered to be a third world ...   \n",
       "244924  I know that the Milky Way is the Galaxy holds ...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "345176  What are the easiest ways to make good money u...             1   \n",
       "388401                                       What is √-1?             0   \n",
       "53958   Which blog platform is better: WordPress or Bl...             0   \n",
       "16213                    Is mexico a third world country?             0   \n",
       "244924  Why didn't any of the other planets in the Sol...             0   \n",
       "\n",
       "        len_q1  len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  \\\n",
       "345176      24      64       -40           12           19            5   \n",
       "388401      10      12        -2            8           10            3   \n",
       "53958       95      52        43           28           21           13   \n",
       "16213       54      32        22           18           19           10   \n",
       "244924     109     151       -42           27           26           20   \n",
       "\n",
       "        len_word_q2  common_words  fuzz_QRatio  fuzz_WRatio  \\\n",
       "345176           12             2           44           86   \n",
       "388401            3             2           90           95   \n",
       "53958             8             2           46           86   \n",
       "16213             6             5           67           86   \n",
       "244924           29             5           44           52   \n",
       "\n",
       "        fuzz_partial_ratio  fuzz_partial_token_set_ratio  \\\n",
       "345176                  58                           100   \n",
       "388401                  80                           100   \n",
       "53958                   56                           100   \n",
       "16213                   78                           100   \n",
       "244924                  50                           100   \n",
       "\n",
       "        fuzz_partial_token_sort_ratio  fuzz_token_set_ratio  \\\n",
       "345176                             61                    61   \n",
       "388401                            100                   100   \n",
       "53958                              54                    67   \n",
       "16213                              65                    87   \n",
       "244924                             61                    53   \n",
       "\n",
       "        fuzz_token_sort_ratio  \n",
       "345176                     42  \n",
       "388401                    100  \n",
       "53958                      58  \n",
       "16213                      62  \n",
       "244924                     55  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies with 10-fold cross validation: \n",
      "0.6624700091518464\n",
      "0.6595018427366495\n",
      "0.6580424942491776\n",
      "0.6603428232209553\n",
      "0.6594276385762695\n",
      "0.6588340052932301\n",
      "0.6622721313908333\n",
      "0.662841029953746\n",
      "0.6626184174726063\n",
      "0.6685052808627471\n",
      "Average: 0.6614855672908061\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "cv_accuracies = []\n",
    "for train, val in kf.split(data[fs_1 + fs_2]):\n",
    "    train_X = np.array(data[fs_1 + fs_2])[train]\n",
    "    train_y = np.array(data['is_duplicate'])[train]\n",
    "    val_X = np.array(data[fs_1 + fs_2])[val]\n",
    "    val_y = np.array(data['is_duplicate'])[val]\n",
    "    \n",
    "    lr_model = LogisticRegression(max_iter=1000, random_state=1)\n",
    "    lr_model.fit(train_X, train_y)\n",
    "    lr_prediction = lr_model.predict(val_X)\n",
    "    \n",
    "    cv_accuracies.append(metrics.accuracy_score(val_y, lr_prediction))\n",
    "\n",
    "average = sum(cv_accuracies)/n_splits\n",
    "\n",
    "print('Accuracies with ' + str(n_splits) + '-fold cross validation: ')\n",
    "for cv_accuracy in cv_accuracies:\n",
    "    print(cv_accuracy)\n",
    "\n",
    "print('Average: ' + str(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies with 10-fold cross validation: \n",
      "0.729130079893146\n",
      "0.7279675480471939\n",
      "0.725469341314403\n",
      "0.7314304088649237\n",
      "0.7252961982735165\n",
      "0.7267060773207351\n",
      "0.7288085285314997\n",
      "0.7283633035692201\n",
      "0.7286106507704865\n",
      "0.7275717925251676\n",
      "Average: 0.7279353929110292\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "cv_accuracies = []\n",
    "for train, val in kf.split(data[fs_1 + fs_2]):\n",
    "    train_X = np.array(data[fs_1 + fs_2])[train]\n",
    "    train_y = np.array(data['is_duplicate'])[train]\n",
    "    val_X = np.array(data[fs_1 + fs_2])[val]\n",
    "    val_y = np.array(data['is_duplicate'])[val]\n",
    "    \n",
    "    xgb_model = XGBClassifier(n_estimators=500, random_state=1)\n",
    "    xgb_model.fit(train_X, train_y)\n",
    "    xgb_prediction = xgb_model.predict(val_X)\n",
    "    \n",
    "    cv_accuracies.append(metrics.accuracy_score(val_y, xgb_prediction))\n",
    "\n",
    "average = sum(cv_accuracies)/n_splits\n",
    "\n",
    "print('Accuracies with ' + str(n_splits) + '-fold cross validation: ')\n",
    "for cv_accuracy in cv_accuracies:\n",
    "    print(cv_accuracy)\n",
    "\n",
    "print('Average: ' + str(average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=1,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train xgboost with all the data\n",
    "xgb_model = XGBClassifier(n_estimators=500, random_state=1)\n",
    "xgb_model.fit(data[fs_1+fs_2], data['is_duplicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect if new questions are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter first sentence: What is food in Spanish?\n",
      "Enter second sentence: How to say food in Spanish?\n",
      "The sentences you have entered are considered duplicate.\n"
     ]
    }
   ],
   "source": [
    "q1 = input('Enter first sentence: ')\n",
    "q2 = input('Enter second sentence: ')\n",
    "new_data = pd.DataFrame([[q1, q2]], columns=['question1', 'question2'])\n",
    "\n",
    "\n",
    "\n",
    "# length based features\n",
    "new_data['len_q1'] = new_data.question1.apply(lambda x: len(str(x)))\n",
    "new_data['len_q2'] = new_data.question2.apply(lambda x: len(str(x)))\n",
    "# difference in lengths of two questions\n",
    "new_data['diff_len'] = new_data.len_q1 - new_data.len_q2\n",
    "\n",
    "# character length based features\n",
    "new_data['len_char_q1'] = new_data.question1.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "new_data['len_char_q2'] = new_data.question2.apply(lambda x: \n",
    "len(''.join(set(str(x).replace(' ', '')))))\n",
    "\n",
    "# word length based features\n",
    "new_data['len_word_q1'] = new_data.question1.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "new_data['len_word_q2'] = new_data.question2.apply(lambda x: \n",
    "len(str(x).split()))\n",
    "\n",
    "# common words in the two questions\n",
    "new_data['common_words'] = new_data.apply(lambda x: \n",
    "len(set(str(x['question1'])\n",
    ".lower().split())\n",
    ".intersection(set(str(x['question2'])\n",
    ".lower().split()))), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# create fuzzy features\n",
    "new_data['fuzz_QRatio'] = new_data.apply(lambda x: fuzz.QRatio(\n",
    "str(x['question1']), str(x['question2'])), axis=1)\n",
    "new_data['fuzz_WRatio'] = new_data.apply(lambda x: fuzz.WRatio(\n",
    "str(x['question1']), str(x['question2'])), axis=1)\n",
    "\n",
    "new_data['fuzz_partial_ratio'] = new_data.apply(lambda x: \n",
    "fuzz.partial_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "new_data['fuzz_partial_token_set_ratio'] = new_data.apply(lambda x:\n",
    "fuzz.partial_token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "new_data['fuzz_partial_token_sort_ratio'] = new_data.apply(lambda x: \n",
    "fuzz.partial_token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "new_data['fuzz_token_set_ratio'] = new_data.apply(lambda x: \n",
    "fuzz.token_set_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "new_data['fuzz_token_sort_ratio'] = new_data.apply(lambda x: \n",
    "fuzz.token_sort_ratio(str(x['question1']), \n",
    "str(x['question2'])), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_prediction = xgb_model.predict(new_data[fs_1+fs_2])\n",
    "if xgb_prediction == 1:\n",
    "    print('The sentences you have entered are considered duplicate.')\n",
    "else:\n",
    "    print('The sentences you have entered are considered NOT duplicate.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
